\documentclass[journal, a4paper]{IEEEtran}

% some very useful LaTeX packages include:

%\usepackage{cite}      % Written by Donald Arseneau
                        % V1.6 and later of IEEEtran pre-defines the format
                        % of the cite.sty package \cite{} output to follow
                        % that of IEEE. Loading the cite package will
                        % result in citation numbers being automatically
                        % sorted and properly "ranged". i.e.,
                        % [1], [9], [2], [7], [5], [6]
                        % (without using cite.sty)
                        % will become:
                        % [1], [2], [5]--[7], [9] (using cite.sty)
                        % cite.sty's \cite will automatically add leading
                        % space, if needed. Use cite.sty's noadjust option
                        % (cite.sty V3.8 and later) if you want to turn this
                        % off. cite.sty is already installed on most LaTeX
                        % systems. The latest version can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/cite/

\usepackage{graphicx}   % Written by David Carlisle and Sebastian Rahtz
                        % Required if you want graphics, photos, etc.
                        % graphicx.sty is already installed on most LaTeX
                        % systems. The latest version and documentation can
                        % be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/required/graphics/
                        % Another good source of documentation is "Using
                        % Imported Graphics in LaTeX2e" by Keith Reckdahl
                        % which can be found as esplatex.ps and epslatex.pdf
                        % at: http://www.ctan.org/tex-archive/info/

%\usepackage{psfrag}    % Written by Craig Barratt, Michael C. Grant,
                        % and David Carlisle
                        % This package allows you to substitute LaTeX
                        % commands for text in imported EPS graphic files.
                        % In this way, LaTeX symbols can be placed into
                        % graphics that have been generated by other
                        % applications. You must use latex->dvips->ps2pdf
                        % workflow (not direct pdf output from pdflatex) if
                        % you wish to use this capability because it works
                        % via some PostScript tricks. Alternatively, the
                        % graphics could be processed as separate files via
                        % psfrag and dvips, then converted to PDF for
                        % inclusion in the main file which uses pdflatex.
                        % Docs are in "The PSfrag System" by Michael C. Grant
                        % and David Carlisle. There is also some information
                        % about using psfrag in "Using Imported Graphics in
                        % LaTeX2e" by Keith Reckdahl which documents the
                        % graphicx package (see above). The psfrag package
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/psfrag/

%\usepackage{subfigure} % Written by Steven Douglas Cochran
                        % This package makes it easy to put subfigures
                        % in your figures. i.e., "figure 1a and 1b"
                        % Docs are in "Using Imported Graphics in LaTeX2e"
                        % by Keith Reckdahl which also documents the graphicx
                        % package (see above). subfigure.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/subfigure/

\usepackage{url}        % Written by Donald Arseneau
                        % Provides better support for handling and breaking
                        % URLs. url.sty is already installed on most LaTeX
                        % systems. The latest version can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/other/misc/
                        % Read the url.sty source comments for usage information.

%\usepackage{stfloats}  % Written by Sigitas Tolusis
                        % Gives LaTeX2e the ability to do double column
                        % floats at the bottom of the page as well as the top.
                        % (e.g., "\begin{figure*}[!b]" is not normally
                        % possible in LaTeX2e). This is an invasive package
                        % which rewrites many portions of the LaTeX2e output
                        % routines. It may not work with other packages that
                        % modify the LaTeX2e output routine and/or with other
                        % versions of LaTeX. The latest version and
                        % documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/sttools/
                        % Documentation is contained in the stfloats.sty
                        % comments as well as in the presfull.pdf file.
                        % Do not use the stfloats baselinefloat ability as
                        % IEEE does not allow \baselineskip to stretch.
                        % Authors submitting work to the IEEE should note
                        % that IEEE rarely uses double column equations and
                        % that authors should try to avoid such use.
                        % Do not be tempted to use the cuted.sty or
                        % midfloat.sty package (by the same author) as IEEE
                        % does not format its papers in such ways.

\usepackage{amsmath}    % From the American Mathematical Society
                        % A popular package that provides many helpful commands
                        % for dealing with mathematics. Note that the AMSmath
                        % package sets \interdisplaylinepenalty to 10000 thus
                        % preventing page breaks from occurring within multiline
                        % equations. Use:
%\interdisplaylinepenalty=2500
                        % after loading amsmath to restore such page breaks
                        % as IEEEtran.cls normally does. amsmath.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/



% Other popular packages for formatting tables and equations include:

%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty which improves the
% LaTeX2e array and tabular environments to provide better appearances and
% additional user controls. array.sty is already installed on most systems.
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/

% V1.6 of IEEEtran contains the IEEEeqnarray family of commands that can
% be used to generate multiline equations as well as matrices, tables, etc.

% Also of notable interest:
% Scott Pakin's eqparbox package for creating (automatically sized) equal
% width boxes. Available:
% http://www.ctan.org/tex-archive/macros/latex/contrib/supported/eqparbox/

% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
\usepackage{amssymb}
\usepackage{filecontents,lipsum}
\usepackage[noadjust]{cite}

\usepackage{subcaption}


\begin{filecontents*}{references.bib}
@inproceedings{nesterov1983method,
  title={A method of solving a convex programming problem with convergence rate O (1/k2)},
  author={Nesterov, Yurii},
  booktitle={Soviet Mathematics Doklady},
  volume={27},
  number={2},
  pages={372--376},
  year={1983}
}
@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}
@article{zeiler2012adadelta,
  title={ADADELTA: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
\end{filecontents*}


\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}

% Your document starts here!
\begin{document}
\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 %----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

~\\[1cm]
\includegraphics{SCUT.png}\\[2cm] % Include a department/university logo - this will require the graphicx package

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[1cm]
{ \huge \bfseries The Experiment Report of \textit{Deep Learning} }\\[0.6cm] % Title of your document
\HRule \\[2cm]
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------


\textsc{\LARGE \textbf{School:} School of Software Engineering}\\[1cm]
\textsc{\LARGE \textbf{Subject:} Software Engineering}\\[2cm]


%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Author:}\\
TengyunWang % Your name
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Supervisor:} \\
Mingkui Tan % Supervisor's Name
\end{flushright}
\end{minipage}\\[2cm]
~
\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Student ID:}\\
201710106574
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Grade:} \\
Graduate
\end{flushright}
\end{minipage}\\[2cm]

% If you don't want a supervisor, uncomment the two lines below and remove the section above
%\Large \emph{Author:}\\
%John \textsc{Smith}\\[3cm] % Your name

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large \today}\\[2cm] % Date, change the \today to a set date if you want to be precise


%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}

% Define document title and author
	\title{Linear Regression, Linear Classification and Gradient Descent}
	\maketitle

% Write abstract here
\begin{abstract}
Optimizer algorithm matters a lot in machine learning. Gradient decent which is one of the most famous algorithms to perform optimization has been applied to solve the optimization problem in machine learning. However, there are many disadvantages in gradient decent. The literature has proposed many gradient decent variances to relieve the insufficient of gradient decent. In this paper, we implement 4 prevailing gradient decent variances and reveal the efficiency of them by conduct experiment in public dataset.
\end{abstract}

% Each section begins with a \section{title} command
\section{Introduction}
	% \PARstart{}{} creates a tall first letter for this first paragraph
\PARstart{G}{radient} descent is one of the most popular algorithms to perform optimization and by far the most common way to optimize neural networks. At the same time, every state-of-the-art Deep Learning library contains implementations of various algorithms to optimize gradient descent (e.g. lasagne's, caffe's, and keras' documentation). These algorithms, however, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by.

% Main Part
\section{Methods and Theory}
There are three variants of gradient descent, which differ in how much data we use to compute the gradient of the objective function. Depending on the amount of data, we make a trade-off between the accuracy of the parameter update and the time it takes to perform an update.

\subsection{Stochastic gradient descent}
Stochastic gradient descent(SGD) in contrast performs a parameter update for each training example $x_i$ and label $y_i$:

\begin{equation}
\label{eq:SGD_theta}
\theta=\theta-\eta \nabla_\theta J(\theta;x_i,y_i)
\end{equation}

Batch gradient descent performs redundant computations for large datasets, as it recomputes gradients for similar examples before each parameter update. SGD does away with this redundancy by performing one update at a time. It is therefore usually much faster and can also be used to learn online.

\subsection{Mini-batch gradient descent}
Mini-batch gradient descent finally takes the best of both worlds and performs an update for every mini-batch of $n$ training examples:

\begin{equation}
\label{eq:MBGD_theta}
\theta=\theta-\eta \nabla_\theta J(\theta;x_{i:i+n},y_{i:i+n})
\end{equation}

This way, it a) reduces the variance of the parameter updates, which can lead to more stable convergence; and b) can make use of highly optimized matrix optimizations common to state-of-the-art deep learning libraries that make computing the gradient w.r.t. a mini-batch very efficient.

\subsection{Nesterov accelerated gradient}
Nesterov accelerated gradient(NAG)\cite{nesterov1983method} is a way to give our momentum term this kind of prescience. We know that we will use our momentum term $\gamma v_{t-1}$ to move the parameters $\theta$. Computing $\theta-\gamma v_{t-1}$ thus gives us an approximation of the next position of the parameters (the gradient is missing for the full update), a rough idea where our parameters are going to be. We can now effectively look ahead by calculating the gradient not w.r.t. to our current parameters $\theta$ but w.r.t. the approximate future position of our parameters:

\begin{equation}
\label{eq:NAG_vt}
v_t=\gamma v_{t-1}+\eta\nabla_\theta J(\theta-\gamma v_{t-1})
\end{equation}

\begin{equation}
\label{eq:NAG_theta_update}
\theta_{t+1}=\theta_t-v_t
\end{equation}

\subsection{Adadelta}
Adadelta\cite{zeiler2012adadelta} is an extension of Adagrad that seeks to reduce its aggressive, monotonically decreasing learning rate.

Instead of inefficiently storing w previous squared gradients, the sum of gradients is recursively defined as a decaying average of all past squared gradients. The running average $E[g^2]_t$ at time step $t$ then depends (as a fraction $\gamma$ similarly to the Momentum term) only on the previous average and the current gradient:

\begin{equation}
\label{eq:Adadelta_E_g}
E[g^2]_t=\gamma E[g^2]_{t-1}+(1-\gamma)g^2_t
\end{equation}

We set $\gamma$ to a similar value as the momentum term, around 0.9. For clarity, we now rewrite our vanilla SGD update in terms of the parameter update vector $\nabla\theta_t$:

\begin{equation}
\label{eq:Adadelta_delta_theta}
\Delta\theta_t=g_t
\end{equation}

\begin{equation}
\label{eq:Adadelta_theta_update}
\theta_{t+1}=\theta_t-\eta\Delta\theta_t
\end{equation}

The parameter update vector of Adagrad that we derived previously thus takes the form:
\begin{equation}
\label{eq:Adadelta_delta_theta_2}
\Delta\theta_t=\frac{1}{\sqrt{G_t+\epsilon}}\odot g_t
\end{equation}

We now simply replace the diagonal matrix $G_t$ with the decaying average over past squared gradients $E[g^2]_t$:

\begin{equation}
\label{eq:Adadelta_delta_theta_3}
\Delta\theta_t=\frac{1}{\sqrt{E[g^2]_t+\epsilon}}\odot g_t
\end{equation}

As the denominator is just the root mean squared (RMS) error criterion of the gradient, we can replace it with the criterion short-hand:

\begin{equation}
\label{eq:Adadelta_delta_theta_4}
\Delta\theta_t=\frac{1}{RMS[g]_t}g_t
\end{equation}

The authors note that the units in this update (as well as in SGD, Momentum, or Adagrad) do not match, i.e. the update should have the same hypothetical units as the parameter. To realize this, they first define another exponentially decaying average, this time not of squared gradients but of squared parameter updates:

\begin{equation}
\label{eq:Adadelta_E_delta_theta}
E[\Delta\theta^2]_t=\gamma E[\Delta\theta^2]_{t-1}+(1-\gamma)\Delta\theta^2_t
\end{equation}

The root mean squared error of parameter updates is thus:

\begin{equation}
\label{eq:Adadelta_RMS_delta_theta}
RMS[\Delta\theta]_t=\sqrt{E[\Delta\theta^2]_t+\epsilon}
\end{equation}

Since $RMS[\Delta\theta]_t$ is unknown, we approximate it with the RMS of parameter updates until the previous time step. Replacing the learning rate $\eta$ in the previous update rule with $RMS[\Delta\theta]_{t-1}$ finally yields the Adadelta update rule:

\begin{equation}
\label{eq:Adadelta_delta_theta_final}
\Delta\theta_t=\frac{RMS[\Delta\theta]_{t-1}}{RMS[g]_t}g_t
\end{equation}

\begin{equation}
\label{eq:Adadelta_theta_final}
\theta_{t-1}=\theta_t-\eta\Delta\theta_t
\end{equation}

\subsection{RMSprop}
RMSprop is an unpublished, adaptive learning rate method proposed by Geoff Hinton in Lecture 6e of his Coursera Class.

RMSprop and Adadelta have both been developed independently around the same time stemming from the need to resolve Adagrad's radically diminishing learning rates. RMSprop in fact is identical to the first update vector of Adadelta that we derived above:

\begin{equation}
\label{eq:RMSprop_E_g}
E[g^2]_t=0.9E[g^2]_{t-1}+0.1g^2_t
\end{equation}

\begin{equation}
\label{eq:RMSprop_theta}
\theta_{t+1}=\theta_t-\frac{\eta}{\sqrt{E[g^2]_t+\epsilon}}g_t
\end{equation}

\subsection{Adam}
Adaptive Moment Estimation(Adam)\cite{kingma2014adam} is another method that computes adaptive learning rates for each parameter. In addition to storing an exponentially decaying average of past squared gradients $v_t$ like Adadelta and RMSprop, Adam also keeps an exponentially decaying average of past gradients $m_t$ , similar to momentum:

\begin{equation}
\label{eq:Adam_m}
m_t=\beta_1 m_{t-1}+(1-\beta_1)g_t
\end{equation}

\begin{equation}
\label{eq:Adam_v}
v_t=\beta_2 m_{t-1}+(1-\beta_2)g^2_t
\end{equation}

$m_t$ and $v_t$ are estimates of the first moment (the mean) and the second moment (the uncentered variance) of the gradients respectively, hence the name of the method. As $m_t$ and $v_t$ are initialized as vectors of 0's, the authors of Adam observe that they are biased towards zero, especially during the initial time steps, and especially when the decay rates are small.

They counteract these biases by computing bias-corrected first and second moment estimates:

\begin{equation}
\label{eq:Adam_m_hat}
\hat{m_t}=\frac{m_t}{1-\beta^t_1}
\end{equation}

\begin{equation}
\label{eq:Adam_v_hat}
\hat{v_t}=\frac{v_t}{1-\beta^t_2}
\end{equation}

They then use these to update the parameters just as we have seen in Adadelta and RMSprop, which yields the Adam update rule:

\begin{equation}
\label{eq:Adam_theta}
\theta_{t+1}=\theta_t-\frac{\eta}{\sqrt{\hat{v_t}+\epsilon}}\hat{m_t}
\end{equation}

\section{Experiments}
\subsection{Dataset}
Experiment uses a9a of LIBSVM Data, including 32561/16281(testing) samples and each sample has 123/123 (testing) features.

\subsection{Implementation}
In this experiment, we adopt logistic regression and soft margin linear support vector machine as our basic model to exam the efficiency of different algorithm.

\subsubsection{Logistic Regression}
The hypothesis of logistic regression is
\begin{equation}
\label{eq:LR_h}
h(x;w,b)=\frac{1}{1+e^{-(w^Tx+b)}}
\end{equation}

The negative value is $-1$, and the positive value is $+1$. We use the negative likelihood loss and the loss function is derived as follows
\begin{equation}
\begin{aligned}
\label{eq:LR_L}
L=& \frac{1}{2N}*\frac{1}{2}\sum_{i=1}^{N}-log(h(x_i))(1+y_i)-log(1-h(x_i))(1-y_i)\\
& +\frac{1}{2}\lambda (\left \|w  \right \|^2+\left \| b \right \|^2)
\end{aligned}
\end{equation}

The derivative of loss function is
\begin{equation}
\label{eq:LR_L_derivative}
L'=\frac{1}{N}\sum_{i=1}^{N}x_i(2h(x_i)-(y_i+1))+\lambda (w+b)
\end{equation}

\subsubsection{Soft-Margin SVM}
The optimization objective of SVM is to find a hyperplane which achieves a good separation and has the largest distance to the nearest training-data point of any class. Soft-margin SVM allows misclassification and the optimization objective is defined as follows

\begin{equation}
\begin{aligned}
\label{eq:SVM_obj}
& \argmin_{w,b,\varepsilon}&& \frac{\left \|w  \right \|^2}{2}+C\sum_{i=1}^{N}\varepsilon_i\\
& \text{subject to} && y_i(w^Tx_i+b)\geqslant 1-\varepsilon_i,\\
& && \varepsilon_i\geqslant 0
\end{aligned}
\end{equation}

Thus the loss function of soft-margin SVM is
\begin{equation}
\label{eq:SVM_L}
L=\frac{1}{N}\sum_{i=1}^{N}C*hinge\_loss(x_i,y_i)+\frac{1}{2}\lambda (\left \|w  \right \|^2+\left \| b \right \|^2)
\end{equation}

\begin{equation}
\label{eq:SVM_hinge_loss}
hinge\_loss(x,y;w,b)=max(0,1-y*(w^Tx+b))
\end{equation}

Loss function`s derivative is
\begin{equation}
\label{eq:SVM_L_derivative}
L'=-\frac{C}{N}\sum_{i=1}^{N}x_iy_i\mathbb {I}[hinge\_loss(x_i,y_i)>0]+\lambda (w+b)
\end{equation}

\subsection{Experiment Setup}
We dived experiment into two parts. In the first part, we empirically initialize the hyper-parameters which will be used in mini-batch gradient decent, NAG£¬RMSProp£¬AdaDelta and Adam. Then we draw the loss`s changing curve of NAG£¬RMSProp£¬AdaDelta and Adam accordingly. In the second part, we tuning the hyper-parameters by exhaustive gird search. Then we give the loss's changing curve too.

In both parts, we set the iterations to 50 which means that we use the whole training set 50 times to perform the gradient decent.
The batch size is set to 8000, means that we use 8000 records in each epoch.

\subsection{Experiment Part One}
The un-tuned logistic regression models` performance are display in Fig.\ref{fig:LR_untuned}
\begin{figure}[!hbt]
	\begin{center}
	\includegraphics[width=\columnwidth]{img/LR_untuned}
	\caption{LR models` simulation results on public dataset. The hyper-parameters are set by expert knowledge.}
	\label{fig:LR_untuned}
	\end{center}
\end{figure}

The un-tuned SVM models` performance are display in Fig.\ref{fig:SVM_untuned}
\begin{figure}[!hbt]
	\begin{center}
	\includegraphics[width=\columnwidth]{img/SVM_untuned}
	\caption{SVM models` simulation results on public dataset. The hyper-parameters are set by expert knowledge.}
	\label{fig:SVM_untuned}
	\end{center}
\end{figure}

We can figure out from Fig.\ref{fig:LR_untuned} and Fig.\ref{fig:SVM_untuned} that
with mini-bath gradient decent and no tuning, RMSprop, Adam, NAG reach convergence within 50 epochs. Adadelta needs 100+ epochs to converge and GD needs 400+ epochs.
Thus, RMSprop, Adam, NAG make fast and satisfied convergence.


\subsection{Experiment Part Two}
In this section, we use exhaustive grid search to tuning the hyper-parameters of models.
We should define the search grid firstly. We share the hyper-parameters` grid in LR and SVM.
The grid is list in Tab. \ref{tab:LR_grid}.
For Adam, there are two additional hyper-parameters which are $\beta_1$ and $\beta_2$. And the candidates are ${0.9, 0.95}$ and ${0.99, 0.999}$ accordingly.
Then, we use 3 fold cross validation to pick out the best combination of hyper-parameters in each algorithm.
The judging metric is the classification accuracy in validation set.
The loss changing curves and accuracy changing curves of GD, NAG, Adadelta, RMSprop, Adam in LR models and SVM models are displayed in Fig. \ref{fig:LR_loss_accuracy} and Fig. \ref{fig:SVM_loss_accuracy} accordingly.
It is interesting that the accuracy does not take a strict inverse ratio to loss for SVM model, and three of the algorithm vibrate a lot although the loss function has reach a convergence. 
This means that there are many uncertain samples near the decision boundary.




Finally, we leave out the accuracy changing curves and put the all loss changing curves together in Fig.\ref{fig:LR_tuned} and Fig.\ref{fig:SVM_tuned} to demonstrate the performance clearly. 
And this two figures show the performance of tuned models. In these two figures we can see that all of five algorithm perform similarly for LR model. And for SVM model, Adam and Adadelta work a little better.
Gradient decent has high-efficiency if given a appropriate learning rate.

\begin{figure}[!hbt]
	\begin{center}
	\includegraphics[width=\columnwidth]{img/LR_tuned}
	\caption{LR models` simulation results on public dataset. The hyper-parameters are tuned by exhaustive gird search.}
	\label{fig:LR_tuned}
	\end{center}
\end{figure}
\begin{figure}[!hbt]
	\begin{center}
	\includegraphics[width=\columnwidth]{img/SVM_tuned}
	\caption{SVM models` simulation results on public dataset. The hyper-parameters are tuned by exhaustive gird search.}
	\label{fig:SVM_tuned}
	\end{center}
\end{figure}

\begin{table}[!hbt]
	\begin{center}
	\caption{Search Grid of LR}
	\label{tab:LR_grid}
	\begin{tabular}{|c|c|c|c|c|}
        \hline
		& $\lambda$ &$\eta$ &$\gamma$ &$threshold$ \\
        \hline
		NAG & 0.01, 0.1 & 0.01, 0.05 &0.8, 0.9, 0.95 &0.5, 0.6 \\
        \hline
		Adadelta & 0.01, 0.1 & None &0.8, 0.9, 0.95 &0.5, 0.6 \\
        \hline
		RMSprop & 0.01, 0.1 & 0.01, 0.05 &None&0.5, 0.6 \\
        \hline
		Adam & 0.01, 0.1 & 0.01, 0.05 &None &0.5, 0.6 \\
        \hline
		GD & 0.01, 0.1, 0.5 & 0.1, 0.2, 0.4, 0.5 &None &0.4, 0.5, 0.6 \\
        \hline
	\end{tabular}
	\end{center}
\end{table}

\section{Conclusion}
Gradient decent is indeed a resultful optimization algorithm. But it has strongly dependency on hyper-parameters especially $\eta$. The four gradient decent variants work remarkable although without the tuning.
In practice if we can¡¯t tuning the hyper-parameters due to the resource limits, we can propose RMSprop or Adam. Both of the algorithm are not so sensitive to hyper-parameters especially learning rate. 

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\columnwidth]{img/LR_NAG_0}
        \caption{NAG}
    \end{subfigure}%
    ~
    \begin{subfigure}[t]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\columnwidth]{img/LR_Adadelta_0}
        \caption{Adadelta}
    \end{subfigure}%
    ~
    \begin{subfigure}[t]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\columnwidth]{img/LR_RMSprop_0}
        \caption{RMSprop}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\columnwidth]{img/LR_Adam_0}
        \caption{Adam}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\columnwidth]{img/LR_GD_0}
        \caption{GD}
    \end{subfigure}

    \caption{The loss changing curve and accuracy changing curve in LR.}
    \label{fig:LR_loss_accuracy}
\end{figure*}
\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\columnwidth]{img/SVM_NAG_0}
        \caption{NAG}
    \end{subfigure}%
    ~
    \begin{subfigure}[t]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\columnwidth]{img/SVM_Adadelta_0}
        \caption{Adadelta}
    \end{subfigure}%
    ~
    \begin{subfigure}[t]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\columnwidth]{img/SVM_RMSprop_0}
        \caption{RMSprop}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\columnwidth]{img/SVM_Adam_0}
        \caption{Adam}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\columnwidth]{img/SVM_GD_0}
        \caption{GD}
    \end{subfigure}

    \caption{The loss changing curve and accuracy changing curve in SVM.}
    \label{fig:SVM_loss_accuracy}
\end{figure*}


\bibliographystyle{ieeetran}
\bibliography{references}
% Your document ends here!
\end{document}
